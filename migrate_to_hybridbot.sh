#!/bin/bash

# QBot to HybridBot Migration Script
# Migriert das QBot Trading System zu GitHub HybridBot Repository

set -e

echo "ðŸš€ QBot to HybridBot Migration Script"
echo "======================================"

# Variablen
QBOT_DIR="/home/pool/qbot"
TEMP_DIR="/tmp/hybridbot-migration"
HYBRIDBOT_REPO="https://github.com/MicBur/hybridbot.git"
USER_EMAIL="micbur1488@gmail.com"
USER_NAME="MicBur"

# Cleanup function
cleanup() {
    echo "ðŸ§¹ Cleaning up temporary files..."
    rm -rf "$TEMP_DIR"
}
trap cleanup EXIT

# 1. Erstelle temporÃ¤res Verzeichnis
echo "ðŸ“ Creating temporary directory..."
mkdir -p "$TEMP_DIR"
cd "$TEMP_DIR"

# 2. Clone HybridBot Repository
echo "ðŸ“¥ Cloning HybridBot repository..."
git clone "$HYBRIDBOT_REPO" .

# Configure git credentials
git config user.email "$USER_EMAIL"
git config user.name "$USER_NAME"

# 3. Erstelle Backend-Ordner
echo "ðŸ“‚ Creating backend directory..."
mkdir -p backend

# 4. Kopiere QBot-Dateien (ohne Git und sensitive Daten)
echo "ðŸ“‹ Copying QBot files to backend..."
cd "$QBOT_DIR"

# Kopiere Kern-Dateien
cp worker.py "$TEMP_DIR/backend/"
cp docker-compose.yml "$TEMP_DIR/backend/"
cp Dockerfile "$TEMP_DIR/backend/"
cp Dockerfile.yfinance "$TEMP_DIR/backend/"
cp requirements.txt "$TEMP_DIR/backend/"
cp init.sql "$TEMP_DIR/backend/"
cp redis-endpoints.txt "$TEMP_DIR/backend/"

# Kopiere Konfigurationsdateien
cp backend.txt "$TEMP_DIR/backend/" 2>/dev/null || echo "âš ï¸  backend.txt not found, skipping..."
cp at.txt "$TEMP_DIR/backend/" 2>/dev/null || echo "âš ï¸  at.txt not found, skipping..."
cp ml.md "$TEMP_DIR/backend/" 2>/dev/null || echo "âš ï¸  ml.md not found, skipping..."
cp README.md "$TEMP_DIR/backend/" 2>/dev/null || echo "âš ï¸  README.md not found, skipping..."
cp RELEASE_NOTES.md "$TEMP_DIR/backend/" 2>/dev/null || echo "âš ï¸  RELEASE_NOTES.md not found, skipping..."
cp LICENSE "$TEMP_DIR/backend/" 2>/dev/null || echo "âš ï¸  LICENSE not found, skipping..."

# Kopiere Python-Scripts
cp grok_top_stocks.py "$TEMP_DIR/backend/" 2>/dev/null || echo "âš ï¸  grok_top_stocks.py not found, skipping..."
cp multi_api_enhanced_service.py "$TEMP_DIR/backend/" 2>/dev/null || echo "âš ï¸  multi_api_enhanced_service.py not found, skipping..."
cp yfinance_enhanced_service.py "$TEMP_DIR/backend/" 2>/dev/null || echo "âš ï¸  yfinance_enhanced_service.py not found, skipping..."
cp yfinance_service.py "$TEMP_DIR/backend/" 2>/dev/null || echo "âš ï¸  yfinance_service.py not found, skipping..."

# Kopiere ML-Modelle (falls vorhanden)
if [ -d "autogluon_model" ]; then
    echo "ðŸ¤– Copying AutoGluon models..."
    cp -r autogluon_model "$TEMP_DIR/backend/"
fi
if [ -d "autogluon_model_15" ]; then
    cp -r autogluon_model_15 "$TEMP_DIR/backend/"
fi
if [ -d "autogluon_model_30" ]; then
    cp -r autogluon_model_30 "$TEMP_DIR/backend/"
fi
if [ -d "autogluon_model_60" ]; then
    cp -r autogluon_model_60 "$TEMP_DIR/backend/"
fi

# Kopiere Qt-Frontend (falls vorhanden)
if [ -d "qt-frontend" ]; then
    echo "ðŸ–¥ï¸  Copying Qt frontend..."
    cp -r qt-frontend "$TEMP_DIR/backend/"
fi
if [ -d "qml" ]; then
    cp -r qml "$TEMP_DIR/backend/"
fi

# Kopiere Scripts-Ordner (falls vorhanden)
if [ -d "scripts" ]; then
    echo "ðŸ“œ Copying scripts..."
    cp -r scripts "$TEMP_DIR/backend/"
fi

# 5. Erstelle sanitized .env.example
echo "ðŸ” Creating sanitized .env.example..."
cat > "$TEMP_DIR/backend/.env.example" << 'EOF'
# QBot Trading Backend Environment Configuration
# Copy this file to .env and fill in your actual API keys

# Database Configuration
DATABASE_URL=postgresql://postgres:pass123@postgres:5432/qt_trade
POSTGRES_PASSWORD=pass123

# Redis Configuration
REDIS_URL=redis://:pass123@redis:6379/0
REDIS_PASSWORD=pass123

# Trading API Keys
ALPACA_API_KEY=your_alpaca_api_key_here
ALPACA_SECRET_KEY=your_alpaca_secret_key_here
ALPACA_BASE_URL=https://paper-api.alpaca.markets

# Market Data API Keys
FINNHUB_API_KEY=your_finnhub_api_key_here
FMP_API_KEY=your_fmp_api_key_here
TWELVEDATA_API_KEY=your_twelvedata_api_key_here
MARKETSTACK_API_KEY=your_marketstack_api_key_here

# AI/ML APIs
GROK_API_KEY=your_grok_api_key_here
GROK_API_URL=https://api.x.ai/v1

# Trading Configuration
DEVIATION_THRESHOLD=0.08
TRAIN_MIN_ROWS=150

# System Configuration
LOG_LEVEL=INFO
DEBUG=false

# Docker Configuration
COMPOSE_PROJECT_NAME=qbot
EOF

# 6. Erstelle Backend-spezifische README.md
echo "ðŸ“š Creating backend README..."
cat > "$TEMP_DIR/backend/README.md" << 'EOF'
# QBot Trading Backend

ðŸ¤– **Multi-Horizon ML Trading System** with Real-time Market Data Integration

## Features

### ðŸ§  Machine Learning
- **AutoGluon Multi-Horizon Models**: 15min, 30min, 60min prediction horizons
- **Automatic Retraining**: Triggers when prediction deviation >8%
- **Model Types**: LightGBM, XGBoost, CatBoost, Neural Networks, Ensemble Methods
- **Performance Tracking**: MAE, MAPE, RÂ² metrics with historical tracking

### ðŸ“Š Multi-API Data Integration
- **Finnhub** âœ… (Primary): Real-time market data
- **TwelveData** âœ… (Secondary): Enhanced market coverage  
- **FMP** âš¡ (Available): Financial fundamentals
- **Marketstack** âš¡ (Available): Additional market data
- **Cross-Validation**: Data quality through source comparison

### ðŸ’° Trading Engine
- **Alpaca API**: Real-time trading execution
- **Risk Management**: Daily caps, position limits, cooldowns
- **Market Hours Safety**: Auto-stop during market closure
- **Trade Logging**: Comprehensive trade history and analytics

### ðŸ—ï¸ Architecture
- **Docker Containerized**: Redis, PostgreSQL, Python Worker
- **Celery Tasks**: Scheduled data fetching, ML training, trading
- **Real-time Communication**: Redis pub/sub for frontend integration
- **Comprehensive Monitoring**: System health, API status, performance metrics

## Quick Start

```bash
# 1. Setup environment
cp .env.example .env
# Edit .env with your API keys

# 2. Start services
docker-compose up -d

# 3. Check system status
docker-compose logs -f worker
```

## API Documentation

See `redis-endpoints.txt` for complete Redis API documentation including:
- Trading controls and status
- ML model metrics and predictions  
- Market data and analytics
- System monitoring endpoints

## ML Model Performance

Current model metrics (example):
```json
{
  "15min": {"mae": 148.42, "mape": 1.93, "r2": 0.85},
  "30min": {"mae": 156.78, "mape": 2.14, "r2": 0.82}, 
  "60min": {"mae": 165.23, "mape": 2.45, "r2": 0.79}
}
```

## System Requirements

- Docker & Docker Compose
- 4GB+ RAM (for AutoGluon ML models)
- API keys for market data and trading services

## Development

```bash
# Install dependencies
pip install -r requirements.txt

# Run worker locally
python worker.py

# Run specific ML training
docker exec qbot-worker-1 python -c "from worker import train_model; train_model.delay('manual')"
```

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Market APIs   â”‚    â”‚   ML Training   â”‚    â”‚   Trading API   â”‚
â”‚  Finnhub/Twelveâ”‚â”€â”€â”€â”€â”‚   AutoGluon     â”‚â”€â”€â”€â”€â”‚   Alpaca API    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Redis + Postgresâ”‚
                    â”‚   Data Layer     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Worker Process â”‚
                    â”‚   (Celery)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## License

MIT License - See LICENSE file for details.
EOF

# 7. Erstelle .gitignore fÃ¼r Backend
echo "ðŸš« Creating .gitignore..."
cat > "$TEMP_DIR/backend/.gitignore" << 'EOF'
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
.venv/
venv/
env/
ENV/

# Environment Variables
.env
.env.local
.env.production

# Redis Runtime Files
celerybeat-schedule
dump.rdb

# Logs
logs/
*.log

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Temporary files
*.tmp
*.bak
*.backup
*~

# Database
*.db
*.sqlite3

# Archives
*.zip
*.tar.gz
*.rar
QtTradeFrontend-*.zip
EOF

# 8. Git Operationen
cd "$TEMP_DIR"

echo "ðŸ“ Adding files to git..."
git add backend/

echo "ðŸ’¾ Committing changes..."
git commit -m "feat: Add QBot Trading Backend

ðŸ¤– Multi-Horizon AutoGluon ML Trading System

Features:
- Multi-horizon ML models (15/30/60min predictions)
- Multi-API integration (Finnhub, TwelveData, FMP, Marketstack)
- Real-time trading via Alpaca API
- Docker containerized architecture
- Redis + PostgreSQL data persistence
- Automatic retraining on >8% prediction deviation
- Comprehensive Redis API documentation (481 lines)
- 2859+ lines of core trading logic

Architecture:
- AutoGluon ML: LightGBM, XGBoost, CatBoost, Neural Networks
- Market Data: Cross-validated multi-source aggregation
- Trading Engine: Risk management with market hours safety
- System Monitoring: Complete health and performance tracking

API Coverage: 90.9% with 2 active premium data sources"

echo "ðŸš€ Pushing to GitHub..."
git push origin master

echo ""
echo "âœ… Migration completed successfully!"
echo ""
echo "ðŸŽ¯ QBot Backend is now available at:"
echo "   https://github.com/MicBur/hybridbot/tree/main/backend"
echo ""
echo "ðŸ“Š Next Steps:"
echo "   1. Review the migrated files on GitHub"
echo "   2. Set up GitHub Actions for CI/CD"
echo "   3. Configure Docker Hub integration"
echo "   4. Plan frontend integration"
echo ""
echo "ðŸ”— Repository Structure:"
echo "   hybridbot/"
echo "   â””â”€â”€ backend/"
echo "       â”œâ”€â”€ worker.py              # Core trading logic"
echo "       â”œâ”€â”€ docker-compose.yml     # Container orchestration"
echo "       â”œâ”€â”€ redis-endpoints.txt    # API documentation"
echo "       â”œâ”€â”€ autogluon_model*/      # Trained ML models"
echo "       â”œâ”€â”€ README.md              # Backend documentation"
echo "       â””â”€â”€ .env.example           # Configuration template"
echo ""